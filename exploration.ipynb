{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Luke Waninger\n",
    "Exploring a dataset containing call center tickets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:34.743153Z",
     "start_time": "2018-07-19T00:11:31.749858Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "from notebook_init import *\n",
    "import datetime as dt\n",
    "import itertools\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import multiprocessing\n",
    "from multiprocessing import Lock, Manager, Process, Queue\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as figf\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from scipy.stats import mode, norm\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "tqdm.pandas()\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "UNKNOWN = 'unk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "* change the `cpu_count` variable below if you need to use your computer for other tasks while this notebook runs\n",
    "* to view visualizations this notebook must be ran in Trusted mode\n",
    "* Python version = 3.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:34.754932Z",
     "start_time": "2018-07-19T00:11:34.747759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cores to utilize:   8 of 8\n"
     ]
    }
   ],
   "source": [
    "cpu_count = multiprocessing.cpu_count()\n",
    "print(f'cores to utilize:   {cpu_count} of {multiprocessing.cpu_count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load and clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:34.933957Z",
     "start_time": "2018-07-19T00:11:34.759972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Issue_Resolution</th>\n",
       "      <th>Issue_Category</th>\n",
       "      <th>Issue_Severity</th>\n",
       "      <th>Support_Level</th>\n",
       "      <th>Support_Channel</th>\n",
       "      <th>Building</th>\n",
       "      <th>City</th>\n",
       "      <th>Position</th>\n",
       "      <th>Country</th>\n",
       "      <th>Tenure_Months</th>\n",
       "      <th>Career_Desc</th>\n",
       "      <th>Division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23935</td>\n",
       "      <td>Workaround</td>\n",
       "      <td>Apps</td>\n",
       "      <td>Sev1</td>\n",
       "      <td>Gold</td>\n",
       "      <td>Chat</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Inside Sales</td>\n",
       "      <td>AU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>IC3</td>\n",
       "      <td>D009170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27259</td>\n",
       "      <td>User Education</td>\n",
       "      <td>Apps</td>\n",
       "      <td>Sev1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chat</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Edinburgh</td>\n",
       "      <td>Relationship Management</td>\n",
       "      <td>GB</td>\n",
       "      <td>52.0</td>\n",
       "      <td>IC4</td>\n",
       "      <td>D010405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52587</td>\n",
       "      <td>Resolved by Caller</td>\n",
       "      <td>Apps</td>\n",
       "      <td>Sev2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chat</td>\n",
       "      <td>B0767</td>\n",
       "      <td>Zaventem</td>\n",
       "      <td>Sales Excellence</td>\n",
       "      <td>BE</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D010467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51194</td>\n",
       "      <td>User Education</td>\n",
       "      <td>Apps</td>\n",
       "      <td>Sev3</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Email</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Relationship Management</td>\n",
       "      <td>AU</td>\n",
       "      <td>64.0</td>\n",
       "      <td>IC4</td>\n",
       "      <td>D009170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32585</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Apps</td>\n",
       "      <td>Sev3</td>\n",
       "      <td>Platinum</td>\n",
       "      <td>Chat</td>\n",
       "      <td>MOBILE</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Account Management</td>\n",
       "      <td>AU</td>\n",
       "      <td>34.0</td>\n",
       "      <td>IC2</td>\n",
       "      <td>D009170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Issue_Resolution Issue_Category Issue_Severity Support_Level  \\\n",
       "0       23935          Workaround           Apps           Sev1          Gold   \n",
       "1       27259      User Education           Apps           Sev1           NaN   \n",
       "2       52587  Resolved by Caller           Apps           Sev2           NaN   \n",
       "3       51194      User Education           Apps           Sev3        Silver   \n",
       "4       32585             Unknown           Apps           Sev3      Platinum   \n",
       "\n",
       "  Support_Channel Building       City                 Position Country  \\\n",
       "0            Chat   MOBILE     Sydney             Inside Sales     AU    \n",
       "1            Chat   MOBILE  Edinburgh  Relationship Management     GB    \n",
       "2            Chat    B0767   Zaventem         Sales Excellence     BE    \n",
       "3           Email   MOBILE  Melbourne  Relationship Management     AU    \n",
       "4            Chat   MOBILE     Sydney       Account Management     AU    \n",
       "\n",
       "   Tenure_Months Career_Desc Division  \n",
       "0            6.0         IC3  D009170  \n",
       "1           52.0         IC4  D010405  \n",
       "2            3.0         NaN  D010467  \n",
       "3           64.0         IC4  D009170  \n",
       "4           34.0         IC2  D009170  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tickets.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, we see that most of the raw features are categorical or ordinal variables. In fact, the only quantitative variable is $\\texttt{Tenure_Months}$. Another interesting characteristic of this data is the logical division of sources. On the left we have information regarding the ticket while the right contains information regarding either the agent on call or the individual who generated the ticket. Intrinsically, we have a one to many relationship between tickets and personnel. Separating these two datasets with correct associations gives more room for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:35.276436Z",
     "start_time": "2018-07-19T00:11:34.939162Z"
    },
    "code_folding": [
     1,
     12,
     21,
     31,
     37,
     50
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>category</th>\n",
       "      <th>severity</th>\n",
       "      <th>level</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23935</td>\n",
       "      <td>workaround</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev1</td>\n",
       "      <td>gold</td>\n",
       "      <td>chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27259</td>\n",
       "      <td>user education</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52587</td>\n",
       "      <td>resolved by caller</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51194</td>\n",
       "      <td>user education</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev3</td>\n",
       "      <td>silver</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32585</td>\n",
       "      <td>unknown</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev3</td>\n",
       "      <td>platinum</td>\n",
       "      <td>chat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id          resolution category severity     level channel\n",
       "0      23935          workaround     apps     sev1      gold    chat\n",
       "1      27259      user education     apps     sev1       NaN    chat\n",
       "2      52587  resolved by caller     apps     sev2       NaN    chat\n",
       "3      51194      user education     apps     sev3    silver   email\n",
       "4      32585             unknown     apps     sev3  platinum    chat"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building</th>\n",
       "      <th>city</th>\n",
       "      <th>position</th>\n",
       "      <th>country</th>\n",
       "      <th>tenure</th>\n",
       "      <th>career</th>\n",
       "      <th>division</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mobile</td>\n",
       "      <td>sydney</td>\n",
       "      <td>inside sales</td>\n",
       "      <td>au</td>\n",
       "      <td>6.0</td>\n",
       "      <td>ic3</td>\n",
       "      <td>d009170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mobile</td>\n",
       "      <td>edinburgh</td>\n",
       "      <td>relationship management</td>\n",
       "      <td>gb</td>\n",
       "      <td>52.0</td>\n",
       "      <td>ic4</td>\n",
       "      <td>d010405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b0767</td>\n",
       "      <td>zaventem</td>\n",
       "      <td>sales excellence</td>\n",
       "      <td>be</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d010467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mobile</td>\n",
       "      <td>melbourne</td>\n",
       "      <td>relationship management</td>\n",
       "      <td>au</td>\n",
       "      <td>64.0</td>\n",
       "      <td>ic4</td>\n",
       "      <td>d009170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mobile</td>\n",
       "      <td>sydney</td>\n",
       "      <td>account management</td>\n",
       "      <td>au</td>\n",
       "      <td>34.0</td>\n",
       "      <td>ic2</td>\n",
       "      <td>d009170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  building       city                 position country  tenure career division\n",
       "0   mobile     sydney             inside sales      au     6.0    ic3  d009170\n",
       "1   mobile  edinburgh  relationship management      gb    52.0    ic4  d010405\n",
       "2    b0767   zaventem         sales excellence      be     3.0    NaN  d010467\n",
       "3   mobile  melbourne  relationship management      au    64.0    ic4  d009170\n",
       "4   mobile     sydney       account management      au    34.0    ic2  d009170"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = list(map(str.lower, df.columns))\n",
    "col_map = {\n",
    "    'issue_resolution': 'resolution',\n",
    "    'issue_category':   'category',\n",
    "    'issue_severity':   'severity',\n",
    "    'support_level':    'level',\n",
    "    'support_channel':  'channel',\n",
    "    'tenure_months':    'tenure',\n",
    "    'career_desc':      'career'\n",
    "}\n",
    "df.rename(columns=col_map, inplace=True)\n",
    "\n",
    "tick_cols = [\n",
    "    'unnamed: 0', \n",
    "    'resolution', \n",
    "    'category', \n",
    "    'severity', \n",
    "    'level',\n",
    "    'channel',  \n",
    "]\n",
    "\n",
    "tech_cols = [\n",
    "    'building', \n",
    "    'city', \n",
    "    'position', \n",
    "    'country', \n",
    "    'tenure', \n",
    "    'career', \n",
    "    'division'\n",
    "]\n",
    "\n",
    "numeric_cols = [\n",
    "    'unnamed: 0',\n",
    "    'tenure'\n",
    "]\n",
    "\n",
    "# strip whitespace and convert all cells to lowercase\n",
    "for col in df.columns:\n",
    "    if col in numeric_cols:\n",
    "        continue\n",
    "    \n",
    "    else:\n",
    "        df[col] = df[col].str.strip()\n",
    "        df[col] = df[col].str.lower()\n",
    "\n",
    "# separate tickets and technicians into separate dataframes\n",
    "tickets = df.loc[:, tick_cols]\n",
    "technicians = df.loc[:, tech_cols]\n",
    "\n",
    "# check whether the unnamed ticket column is a valid key, rename if so\n",
    "if (len(df.loc[:, 'unnamed: 0']) == len(pd.unique(df.loc[:, 'unnamed: 0']))):\n",
    "    tmap = {'unnamed: 0':'ticket_id'}\n",
    "    tickets.rename(columns=tmap, inplace=True)\n",
    "    df.rename(columns=tmap, inplace=True)\n",
    "    tick_cols[0] = 'ticket_id'\n",
    "   \n",
    "# drop duplicate technicians\n",
    "technicians = technicians.drop_duplicates(keep='first')\n",
    "\n",
    "tickets.head(5)\n",
    "technicians.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column `unnamed: 0` turned out to be valid key which further implies that no duplicate tickets existed in the frame. Before we do any further data reorganization we need to create a foreign key from ticket to technician in order to maintain data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:50.194882Z",
     "start_time": "2018-07-19T00:11:35.283767Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating keys: 100%|██████████| 10006/10006 [00:14<00:00, 673.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>resolution</th>\n",
       "      <th>category</th>\n",
       "      <th>severity</th>\n",
       "      <th>level</th>\n",
       "      <th>channel</th>\n",
       "      <th>technician</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23935</td>\n",
       "      <td>workaround</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev1</td>\n",
       "      <td>gold</td>\n",
       "      <td>chat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27259</td>\n",
       "      <td>user education</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52587</td>\n",
       "      <td>resolved by caller</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chat</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51194</td>\n",
       "      <td>user education</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev3</td>\n",
       "      <td>silver</td>\n",
       "      <td>email</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32585</td>\n",
       "      <td>unknown</td>\n",
       "      <td>apps</td>\n",
       "      <td>sev3</td>\n",
       "      <td>platinum</td>\n",
       "      <td>chat</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticket_id          resolution category severity     level channel  \\\n",
       "0      23935          workaround     apps     sev1      gold    chat   \n",
       "1      27259      user education     apps     sev1       NaN    chat   \n",
       "2      52587  resolved by caller     apps     sev2       NaN    chat   \n",
       "3      51194      user education     apps     sev3    silver   email   \n",
       "4      32585             unknown     apps     sev3  platinum    chat   \n",
       "\n",
       "   technician  \n",
       "0           0  \n",
       "1           1  \n",
       "2           2  \n",
       "3           3  \n",
       "4           4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8569\n"
     ]
    }
   ],
   "source": [
    "tmp = dict()\n",
    "\n",
    "techs = []\n",
    "for idx, row in tqdm(\n",
    "    zip(df.index.tolist(), df.iterrows()), \n",
    "    total=len(df), \n",
    "    desc='generating keys'\n",
    "):\n",
    "    key = '.'.join([str(a) for a in row[1][tech_cols]])\n",
    "    \n",
    "    if key not in tmp.keys():\n",
    "        tmp[key] = idx\n",
    "        val = idx\n",
    "    else:\n",
    "        val = tmp[key]\n",
    "    \n",
    "    techs.append(val)\n",
    "\n",
    "tickets['technician'] = techs\n",
    "tickets.head(5)\n",
    "print(len(pd.unique(tickets.technician)))\n",
    "\n",
    "del tmp, techs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've found around 2500 duplicate persons and mapped them as foreign keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:50.254916Z",
     "start_time": "2018-07-19T00:11:50.199180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>category</th>\n",
       "      <th>accounts</th>\n",
       "      <th>apps</th>\n",
       "      <th>help</th>\n",
       "      <th>infrastructure</th>\n",
       "      <th>other</th>\n",
       "      <th>phone</th>\n",
       "      <th>software</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resolution</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hardware repair</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>known error</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-actionable</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-reproducible</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reimaged</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>request complete</th>\n",
       "      <td>0</td>\n",
       "      <td>603</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resolved by caller</th>\n",
       "      <td>0</td>\n",
       "      <td>463</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software update</th>\n",
       "      <td>0</td>\n",
       "      <td>639</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown</th>\n",
       "      <td>0</td>\n",
       "      <td>1764</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user edacution</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user educate</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user education</th>\n",
       "      <td>1</td>\n",
       "      <td>2272</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workaround</th>\n",
       "      <td>1</td>\n",
       "      <td>3535</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "category            accounts  apps  help  infrastructure  other  phone  \\\n",
       "resolution                                                               \n",
       "hardware repair            0     9     0               0      0      0   \n",
       "known error                0     0     0               0      0      0   \n",
       "non-actionable             0    61   291               0      0      0   \n",
       "non-reproducible           0    83     2               1      0      0   \n",
       "reimaged                   0     3     0               0      0      0   \n",
       "request complete           0   603    15               5      0      0   \n",
       "resolved by caller         0   463    12               2      0      2   \n",
       "software update            0   639     4               4      0      2   \n",
       "unknown                    0  1764    15              10      0      4   \n",
       "user edacution             0     1     0               0      1      0   \n",
       "user educate               3     0     0               0      0      0   \n",
       "user education             1  2272    59               4      0      2   \n",
       "workaround                 1  3535    35              10      0      7   \n",
       "\n",
       "category            software  \n",
       "resolution                    \n",
       "hardware repair            0  \n",
       "known error                2  \n",
       "non-actionable             0  \n",
       "non-reproducible           0  \n",
       "reimaged                   0  \n",
       "request complete           0  \n",
       "resolved by caller         0  \n",
       "software update            0  \n",
       "unknown                    0  \n",
       "user edacution             0  \n",
       "user educate               1  \n",
       "user education             0  \n",
       "workaround                 0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(tickets.resolution, tickets.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:50.292149Z",
     "start_time": "2018-07-19T00:11:50.259471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel\n",
      "-----------------------------\n",
      "email    5305\n",
      "chat     3812\n",
      "phone     889\n",
      "Name: channel, dtype: int64\n",
      "\n",
      "level\n",
      "-----------------------------\n",
      "NaN         8885\n",
      "silver       929\n",
      "gold         140\n",
      "platinum      52\n",
      "Name: level, dtype: int64\n",
      "\n",
      "category\n",
      "-----------------------------\n",
      "apps              9456\n",
      "help               433\n",
      "NaN                 53\n",
      "infrastructure      38\n",
      "phone               17\n",
      "accounts             5\n",
      "software             3\n",
      "other                1\n",
      "Name: category, dtype: int64\n",
      "\n",
      "resolution\n",
      "-----------------------------\n",
      "workaround            3597\n",
      "user education        2338\n",
      "unknown               1811\n",
      "software update        649\n",
      "request complete       623\n",
      "resolved by caller     504\n",
      "non-actionable         352\n",
      "non-reproducible        86\n",
      "NaN                     26\n",
      "hardware repair          9\n",
      "user educate             4\n",
      "reimaged                 3\n",
      "user edacution           2\n",
      "known error              2\n",
      "Name: resolution, dtype: int64\n",
      "\n",
      "severity\n",
      "-----------------------------\n",
      "sev2    6099\n",
      "sev1    2016\n",
      "sev3    1890\n",
      "sev4       1\n",
      "Name: severity, dtype: int64\n",
      "\n",
      "excluded NaN counts\n",
      "-----------------------------\n",
      "ticket_id - 0\n",
      "technician - 0\n"
     ]
    }
   ],
   "source": [
    "evaluation(tickets, exclusions=['ticket_id', 'technician'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We immediately see several commonalities among the responses that we can take advantage of. Particularly, the signal regarding our research question can be increased by binning appropriate columns and reducing the number of features. Additionally, the 'severity' column has an embedded ordering so I'll change it to integer values and treat it as an ordinal variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:50.384827Z",
     "start_time": "2018-07-19T00:11:50.297856Z"
    }
   },
   "outputs": [],
   "source": [
    "# adjust the misspelling\n",
    "edu_forms = ['user education', 'user edacution', 'user educate']\n",
    "tickets['edu'] = tickets.resolution.isin(edu_forms).astype(int)\n",
    "\n",
    "# drop resolution in favor of a binary 'is_edu'\n",
    "tickets = tickets.drop(labels=['resolution'], axis=1)\n",
    "\n",
    "# group the tiny categories\n",
    "tickets.loc[tickets.category.isin(['accounts', 'software', 'other']) | tickets.category.isnull(), 'category'] = 'other'\n",
    "\n",
    "# adjust the severity to make use of the implicit ordering and reset\n",
    "# the single sev4 to sev3\n",
    "tickets.loc[tickets.severity == 'sev1', 'severity'] = 1\n",
    "tickets.loc[tickets.severity == 'sev2', 'severity'] = 2\n",
    "tickets.loc[tickets.severity == 'sev3', 'severity'] = 3\n",
    "tickets.loc[tickets.severity == 'sev4', 'severity'] = 3\n",
    "\n",
    "# set the index to ticket_ids\n",
    "tickets.index = tickets.ticket_id\n",
    "tickets.drop(labels=['ticket_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:50.401037Z",
     "start_time": "2018-07-19T00:11:50.388350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within support level, 88.8% are nan\n"
     ]
    }
   ],
   "source": [
    "print(f'within support level, {np.round(np.sum(tickets.level.isna()/len(tickets)), 3)*100}% are nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support_level column is almost exclusively NaN. Without background knowledge these values could come from two sources: one, the caller didn't have a support plan or two, the data was lost somewhere along the way. For this project, I'm assuming the first and setting the NaNs to 'none'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:50.482633Z",
     "start_time": "2018-07-19T00:11:50.405242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edu\n",
      "-----------------------------\n",
      "0    7662\n",
      "1    2344\n",
      "Name: edu, dtype: int64\n",
      "\n",
      "channel\n",
      "-----------------------------\n",
      "email    5305\n",
      "chat     3812\n",
      "phone     889\n",
      "Name: channel, dtype: int64\n",
      "\n",
      "severity\n",
      "-----------------------------\n",
      "2    6099\n",
      "1    2016\n",
      "3    1891\n",
      "Name: severity, dtype: int64\n",
      "\n",
      "category\n",
      "-----------------------------\n",
      "apps              9456\n",
      "help               433\n",
      "other               62\n",
      "infrastructure      38\n",
      "phone               17\n",
      "Name: category, dtype: int64\n",
      "\n",
      "level\n",
      "-----------------------------\n",
      "none        8885\n",
      "silver       929\n",
      "gold         140\n",
      "platinum      52\n",
      "Name: level, dtype: int64\n",
      "\n",
      "excluded NaN counts\n",
      "-----------------------------\n",
      "technician - 0\n"
     ]
    }
   ],
   "source": [
    "tickets.loc[tickets.level.isnull(), 'level'] = 'none'\n",
    "\n",
    "evaluation(tickets, exclusions=['technician'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technicians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initial munging and imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:50.516011Z",
     "start_time": "2018-07-19T00:11:50.486851Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "career\n",
      "-----------------------------\n",
      "ic4      3222\n",
      "ic3      2388\n",
      "ic5       991\n",
      "ic2       798\n",
      "mgr3      400\n",
      "NaN       184\n",
      "mgr2      156\n",
      "mgr4      149\n",
      "ic6       122\n",
      "ic1       102\n",
      "exec5      20\n",
      "exec4      16\n",
      "mgr5       13\n",
      "mgr6        3\n",
      "exec6       2\n",
      "exec3       2\n",
      "ic7         1\n",
      "Name: career, dtype: int64\n",
      "\n",
      "excluded NaN counts\n",
      "-----------------------------\n",
      "city - 141\n",
      "country - 3\n",
      "division - 0\n",
      "tenure - 6\n",
      "position - 0\n",
      "building - 0\n"
     ]
    }
   ],
   "source": [
    "evaluation(technicians, exclusions=[\n",
    "    'city', 'country', 'division', 'tenure', 'position', 'building'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, there aren't many missing values and of those, city and country might be linear combinations of other fields. First, impute the missing cities and countries by their inherent hierarchy. Find matching buildings and fall back to countries that must match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:51.952452Z",
     "start_time": "2018-07-19T00:11:50.522367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 match(es) found\n",
      "\n",
      "excluded NaN counts\n",
      "-----------------------------\n",
      "building - 0\n",
      "city - 0\n",
      "position - 0\n",
      "country - 3\n",
      "tenure - 6\n",
      "career - 184\n",
      "division - 0\n"
     ]
    }
   ],
   "source": [
    "missing_cities = technicians.loc[technicians.city.isnull(), :]\n",
    "match_count = 0\n",
    "\n",
    "# iterate through each row looking for matching cities by the building\n",
    "# excluding the values 'home office' and 'mobile'\n",
    "for idx, mc in missing_cities.iterrows():\n",
    "    if mc.building == 'home office' or mc.building == 'mobile':\n",
    "        technicians.loc[idx, 'city'] = UNKNOWN\n",
    "        \n",
    "    matches = technicians.loc[\n",
    "        (~technicians.city.isnull()) &\n",
    "        (technicians.country == mc.country)\n",
    "    ]\n",
    "    \n",
    "    # group by the building, find, and set the city\n",
    "    grouped = matches.groupby(by=['building'], axis=0)\n",
    "    if mc.building in grouped.groups.keys():\n",
    "        \n",
    "        # get the group of technicians that work in the same building\n",
    "        group = technicians.loc[grouped.groups[mc.building], :]\n",
    "        \n",
    "        # find and set the matching city\n",
    "        city = pd.Series(group.city.value_counts()).values.argmax\n",
    "        city = group.city.values[city()]\n",
    "        \n",
    "        technicians.loc[idx, 'city'] = city\n",
    "        match_count += 1\n",
    "    else:\n",
    "        technicians.loc[idx, 'city'] = UNKNOWN\n",
    "\n",
    "print(f'{match_count} match(es) found\\n')\n",
    "evaluation(technicians, exclusions=tech_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, impute missing countries by referencing technicians with matching cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:51.986052Z",
     "start_time": "2018-07-19T00:11:51.955691Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 match(es) found\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_countries = technicians.loc[technicians.country.isnull(), :]\n",
    "match_count = 0\n",
    "\n",
    "# iterate through each row looking for matching cities\n",
    "for idx, mc in missing_countries.iterrows():        \n",
    "    matches = technicians.loc[\n",
    "        (technicians.city != UNKNOWN) &\n",
    "        (technicians.city == mc.city)\n",
    "    ]\n",
    "    \n",
    "    # group by the city and find the country it's in\n",
    "    grouped = matches.groupby(by=['city'], axis=0)\n",
    "    if mc.city in grouped.groups.keys():\n",
    "        # get the matching city, then set the matching country\n",
    "        group = technicians.loc[grouped.groups[mc.city], :]\n",
    "        country = pd.Series(group.country.value_counts()).values.argmax\n",
    "        country = group.country.values[country()]\n",
    "        technicians.loc[idx, 'country'] = country\n",
    "        match_count += 1\n",
    "    else:\n",
    "        technicians.loc[idx, 'country'] = UNKNOWN\n",
    "    \n",
    "print(f'{match_count} match(es) found\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:56.438352Z",
     "start_time": "2018-07-19T00:11:51.992214Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a ticket count\n",
    "ticket_counts = pd.DataFrame(tickets.groupby(['technician']).aggregate(len)).iloc[:, 0]\n",
    "technicians['ticket_count'] = np.ones(len(technicians))\n",
    "\n",
    "for i, v in ticket_counts.iteritems():\n",
    "    technicians.loc[i, 'ticket_count'] = v\n",
    "\n",
    "# create binary variables for executive, managers, and ic\n",
    "exec_ = ['exec6', 'exec5', 'exec4', 'exec3']\n",
    "technicians['is_exec'] = [1 if x in exec_ else 0 for x in technicians.career.values]\n",
    "\n",
    "mgr = ['mgr6', 'mgr5', 'mgr4']\n",
    "technicians['is_mgr'] = [1 if x in mgr else 0 for x in technicians.career.values]\n",
    "\n",
    "ic = ['ic7', 'ic6', 'ic5']\n",
    "technicians['is_ic'] = [1 if x in ic else 0 for x in technicians.career.values]\n",
    "\n",
    "t = [tech_cols.append(key) for key in ['ticket_count', 'is_exec', 'is_mgr', 'is_ic']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### binning\n",
    "I join the underrepresented categories for two reasons: one, to give them more influence during training and two: to prevent errors during shuffles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:56.492026Z",
     "start_time": "2018-07-19T00:11:56.442004Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "technicians.loc[technicians.career.isin(exec_), 'career'] = 'exec'\n",
    "technicians.loc[technicians.career.isin(mgr), 'career'] = 'mgr4'\n",
    "technicians.loc[technicians.career.isin(ic), 'career'] = 'ic5'\n",
    "\n",
    "# group the building numbers to 'office' and rename 'home office' to 'home'\n",
    "technicians.loc[technicians.building.str.startswith('b'), 'building'] = 'office'\n",
    "technicians.loc[technicians.building == 'home office', 'building'] = 'home'\n",
    "\n",
    "del exec_, mgr, ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, tenure has only 6 missing values from what should theoretically be an exponential distribution. We can impute these by finding means of correlated observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:56.551319Z",
     "start_time": "2018-07-19T00:11:56.497877Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building</th>\n",
       "      <th>city</th>\n",
       "      <th>position</th>\n",
       "      <th>country</th>\n",
       "      <th>tenure</th>\n",
       "      <th>career</th>\n",
       "      <th>division</th>\n",
       "      <th>ticket_count</th>\n",
       "      <th>is_exec</th>\n",
       "      <th>is_mgr</th>\n",
       "      <th>is_ic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>mobile</td>\n",
       "      <td>san francisco</td>\n",
       "      <td>unassigned</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d015742</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>mobile</td>\n",
       "      <td>elk grove village</td>\n",
       "      <td>unassigned</td>\n",
       "      <td>us</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d006433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2955</th>\n",
       "      <td>mobile</td>\n",
       "      <td>makati city</td>\n",
       "      <td>unassigned</td>\n",
       "      <td>ph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d008459</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6827</th>\n",
       "      <td>office</td>\n",
       "      <td>unk</td>\n",
       "      <td>software engineering</td>\n",
       "      <td>unk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d010405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>office</td>\n",
       "      <td>unk</td>\n",
       "      <td>unassigned</td>\n",
       "      <td>unk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d013149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9135</th>\n",
       "      <td>mobile</td>\n",
       "      <td>shanghai</td>\n",
       "      <td>business evangelist</td>\n",
       "      <td>cn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ic4</td>\n",
       "      <td>d003414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     building               city              position country  tenure career  \\\n",
       "1183   mobile      san francisco            unassigned      us     NaN    NaN   \n",
       "2349   mobile  elk grove village            unassigned      us     NaN    NaN   \n",
       "2955   mobile        makati city            unassigned      ph     NaN    NaN   \n",
       "6827   office                unk  software engineering     unk     NaN    NaN   \n",
       "7020   office                unk            unassigned     unk     NaN    NaN   \n",
       "9135   mobile           shanghai   business evangelist      cn     NaN    ic4   \n",
       "\n",
       "     division  ticket_count  is_exec  is_mgr  is_ic  \n",
       "1183  d015742           1.0        0       0      0  \n",
       "2349  d006433           2.0        0       0      0  \n",
       "2955  d008459           1.0        0       0      0  \n",
       "6827  d010405           1.0        0       0      0  \n",
       "7020  d013149           1.0        0       0      0  \n",
       "9135  d003414           1.0        0       0      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technicians.loc[technicians.tenure.isnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:56.605302Z",
     "start_time": "2018-07-19T00:11:56.554601Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set the missing tenure values to the mean of associated data points\n",
    "mean_tenure = np.mean(technicians.loc[\n",
    "    ((technicians.country == 'ph') |\n",
    "    (technicians.country == 'us')) & \n",
    "    ((technicians.building == 'mobile') |\n",
    "    (technicians.building == 'b0535')), 'tenure']\n",
    ")\n",
    "technicians.loc[technicians.tenure.isnull(), 'tenure'] = mean_tenure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LASSO to impute the missing careers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use LASSO regression with this report because the features are almost exclusively categorical. Many indicator variables will be made and many of which will have no use in the final model. LASSO gives us a way to completely remove their influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:11:58.040904Z",
     "start_time": "2018-07-19T00:11:56.609258Z"
    }
   },
   "outputs": [],
   "source": [
    "x  = technicians.loc[~technicians.career.isnull(), :].dropna()\n",
    "xp = technicians.loc[technicians.career.isnull(), :].fillna(0)\n",
    "y  = x.career.values\n",
    "\n",
    "# generate a label->int mapping\n",
    "labels = pd.unique(y)\n",
    "label_map   = {i:a for a, i in enumerate(labels)}\n",
    "label_map_r = {a:i for a, i in enumerate(labels)}\n",
    "y = np.array([label_map[yi] for yi in y])\n",
    "\n",
    "# drop the useless features\n",
    "x  =  x.drop(labels=['career'], axis=1)\n",
    "xp = xp.drop(labels=['career'], axis=1)\n",
    "\n",
    "# generate indicator variables\n",
    "x  = pd.get_dummies(x)\n",
    "xp = pd.get_dummies(xp)\n",
    "\n",
    "# add the missing sparse features\n",
    "miss_xp = set(x.columns)-set(xp.columns)\n",
    "miss_x  = set(xp.columns)-set(x.columns)\n",
    "for col in miss_xp:\n",
    "    xp[col] = np.zeros(len(xp))\n",
    "\n",
    "for col in miss_x:\n",
    "    x[col] = np.zeros(len(x))\n",
    "        \n",
    "# split and standardize\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=10)\n",
    "\n",
    "scaler  = StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test  = scaler.transform(x_test)\n",
    "xp = scaler.transform(xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T05:47:14.306965Z",
     "start_time": "2018-06-12T05:42:19.733Z"
    }
   },
   "source": [
    "##### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.121062Z",
     "start_time": "2018-07-19T00:11:58.045867Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fitting OvO classifiers:   0%|          | 0/36 [00:00<?, ?it/s]Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 82, in track_it\n",
      "    update = trackq.get()\n",
      "  File \"<string>\", line 2, in get\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/managers.py\", line 757, in _callmethod\n",
      "    kind, result = conn.recv()\n",
      "Process Process-5:\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-17e856e93bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_one\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mvals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mn_cons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\u001b[0m in \u001b[0;36mprod_con_map\u001b[0;34m(func, vals, n_cons)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbrake\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresults_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'END'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "Process Process-8:\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "Process Process-10:\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n",
      "KeyboardInterrupt\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n",
      "KeyboardInterrupt\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "Process Process-4:\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 118, in consumer\n",
      "    rv = func(val)\n",
      "  File \"/mnt/c/Users/lukew/OneDrive/git/CallCenterExploration/notebook_init.py\", line 63, in fit_one\n",
      "    gs = GridSearchCV(clf, params).fit(xt, yt)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 639, in fit\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 779, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 625, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 588, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 111, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 332, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n",
      "    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 752, in fit\n",
      "    check_input=False)\n",
      "  File \"/home/luke/anaconda3/envs/ML/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\", line 477, in enet_path\n",
      "    positive)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# generate a list of all the OvO pairs we need to train\n",
    "pairs = [p for p in itertools.combinations(np.unique(y), 2)]\n",
    "\n",
    "# setup a progress bar\n",
    "pbar, qu = progress_bar(total=len(pairs), desc='fitting OvO classifiers')\n",
    "                        \n",
    "# setup the classifier\n",
    "parameters = {\n",
    "    'alpha': np.linspace(0.1, 5, 10),\n",
    "    'fit_intercept': [True, False],\n",
    "}\n",
    "\n",
    "# fit using the producer consumer parallel pattern\n",
    "clf = Lasso(max_iter=5000, selection='random', copy_X=True)\n",
    "clfs = prod_con_map(\n",
    "    func=fit_one, \n",
    "    vals=[(pair, qu, clf, parameters, x_train, y_train) for pair in pairs], \n",
    "    n_cons=cpu_count\n",
    ")\n",
    "\n",
    "# terminate and close the progres bar\n",
    "pbar.terminate()\n",
    "pbar.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T05:47:14.335251Z",
     "start_time": "2018-06-12T05:43:19.895Z"
    }
   },
   "source": [
    "##### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.125152Z",
     "start_time": "2018-07-19T00:11:31.841Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# make predictions\n",
    "def predict_ovo(x):\n",
    "    yhat, rcoefs = [], []\n",
    "    for clf in clfs:\n",
    "        clf, pos, neg = clf\n",
    "        plab, nlab = label_map_r[pos], label_map_r[neg]\n",
    "\n",
    "        # show the remaining number of coefficients so we can get a \n",
    "        # feeling for the effectiveness of our feature space\n",
    "        rc = np.array([i for i, c in enumerate(clf.best_estimator_.coef_) if c > 0])\n",
    "        rcoefs.append(rc)\n",
    "\n",
    "        t = clf.predict(x)\n",
    "        yhat.append([pos if yhi > 0 else neg for yhi in t])\n",
    "\n",
    "    # take the mode of predicted values, breaking ties at random-uniform\n",
    "    yhat = np.array(yhat).T\n",
    "    yhat = [np.random.choice(mode(r).mode, 1)[0] for r in yhat]    \n",
    "\n",
    "    # smoosh the remaining coefficients\n",
    "    coefs = []\n",
    "    for l in rcoefs:\n",
    "        for e in l:\n",
    "            coefs.append(e)\n",
    "    rcoefs = coefs\n",
    "    \n",
    "    return yhat, rcoefs\n",
    "\n",
    "yhat, rcoefs = predict_ovo(x_test)\n",
    "\n",
    "# show the confusion matrix\n",
    "cm = confusion_matrix(y_test, yhat)\n",
    "\n",
    "fig = plot_confusion_matrix(cm, classes=labels)\n",
    "iplot(fig, filename='cm')\n",
    "\n",
    "# print validation score\n",
    "print(f'\\nfinal validation error: {np.mean(yhat != y_test)}')\n",
    "print(f'of {x_train.shape[1]} features, only {len(np.unique(rcoefs))} were found useful for any model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### impute\n",
    "The validation error isn't to bad considering the number of classes we're predicting. Also note that IC4 tends to pull in the IC3 labels which could indicate that we're underfitting for IC4 or overfitting IC3. I tried several down/up sampling techniques to adjust for this but in the decided that a different model might be a better choice. Let's go ahead and impute the remaining null career entries using the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.127706Z",
     "start_time": "2018-07-19T00:11:31.845Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "yhat, tmp = predict_ovo(xp)\n",
    "\n",
    "# set the imputed\n",
    "idx = technicians.career.isnull()\n",
    "technicians.loc[idx, 'career'] = [label_map_r[yhi] for yhi in yhat]\n",
    "\n",
    "del yhat, tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.130229Z",
     "start_time": "2018-07-19T00:11:31.849Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluation(tickets, exclusions=['technician'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.133684Z",
     "start_time": "2018-07-19T00:11:31.853Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "evaluation(technicians, exclusions=['city', 'country', 'division', 'tenure', 'position'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'd like to make a visual assessment of each indicator. Is it clear that any variable behaves differently for education vs. non-education resolution types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.136121Z",
     "start_time": "2018-07-19T00:11:31.857Z"
    },
    "code_folding": [
     2,
     27,
     46
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# plot predictors w/respect to response\n",
    "df = tickets.join(technicians, on='technician', how='outer')\n",
    "predictors = [\n",
    "    'channel', 'severity', 'category', 'level', 'is_exec', 'is_mgr', 'is_ic', 'building'\n",
    "]\n",
    "\n",
    "# setup the main figure\n",
    "fig = tools.make_subplots(\n",
    "    rows=3, cols=5,\n",
    "    specs=[\n",
    "        [{'rowspan':3}, {'colspan':4}, None, None, None],\n",
    "        [None, {}, {}, {}, {}],\n",
    "        [None, {}, {}, {}, {}]\n",
    "    ],\n",
    "    subplot_titles=(\n",
    "            'Resolved through education',\n",
    "            'Proportions of predictors resolved through education'\n",
    "    ),\n",
    "    print_grid=False\n",
    ")\n",
    "\n",
    "# update subplot sizes\n",
    "fig['layout']['yaxis2'].update(domain=[.95, 1])\n",
    "t = [fig['layout'][f'yaxis{i}'].update(domain=[.55, .95]) for i in [3, 4, 5,  6]]\n",
    "t = [fig['layout'][f'yaxis{i}'].update(domain=[0,  .35])  for i in [7, 8, 9, 10]]\n",
    "\n",
    "# remove the extra ink\n",
    "for idx in [4, 5, 6, 8, 9, 10]:\n",
    "    fig['layout'][f'yaxis{idx}'].update(\n",
    "        ticks='',\n",
    "        showline=False,\n",
    "        zeroline=False,\n",
    "        showticklabels=False\n",
    "    )\n",
    "\n",
    "# generate the main leftside bars and add them to the plot\n",
    "mb0 = go.Bar(\n",
    "        name='other resolution types',\n",
    "        x=['no'],\n",
    "        y=tickets.loc[tickets.edu == 0, 'edu'].value_counts(),\n",
    "        marker=dict(\n",
    "            color=Theme().GREY\n",
    "        ),\n",
    "        xaxis='x1',\n",
    "        yaxis='y1'\n",
    "    )\n",
    "mb1 = go.Bar(\n",
    "        name='solved through user education',\n",
    "        x=['yes'],\n",
    "        y=tickets.loc[tickets.edu == 1, 'edu'].value_counts(),\n",
    "        marker=dict(\n",
    "            color=Theme().ORANGE\n",
    "        ),\n",
    "        xaxis='x1',\n",
    "        yaxis='y1'\n",
    "    )\n",
    "\n",
    "t = fig.append_trace(mb0, 1, 1)\n",
    "t = fig.append_trace(mb1, 1, 1)\n",
    "\n",
    "# create the indicator bars\n",
    "col_idx = 2\n",
    "for ax, predictor in enumerate(predictors, 3):\n",
    "    row = 2 if 3 <= ax <= 6 else 3\n",
    "    col = ax-1 if 3 <= ax <= 6 else ax-5\n",
    "    bars = [] \n",
    "    \n",
    "    for edu in [0, 1]:\n",
    "        series = df.loc[df.edu == edu, predictor]\n",
    "        indicators = pd.unique(df[predictor])    \n",
    "\n",
    "        for i, indicator in enumerate(indicators): \n",
    "            a = len(series[series == indicator])\n",
    "            b = len(series)\n",
    "            y = a/(a+b)\n",
    "\n",
    "            b = go.Bar(\n",
    "                name=indicator,\n",
    "                x=['no' if edu == 0 else 'yes'],\n",
    "                y=[y],\n",
    "                text=indicator,\n",
    "                marker=dict(color=Theme()[i]),\n",
    "                xaxis=f'x{ax}',\n",
    "                yaxis=f'y{ax}'\n",
    "            )\n",
    "            \n",
    "            fig.append_trace(b, row, col)\n",
    "    fig['layout'][f'xaxis{ax}'].update(title=predictor)\n",
    "    \n",
    "fig['layout'].update(barmode='stack', showlegend=False)\n",
    "iplot(fig, filename='issue_bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, theres almost no discernible difference between the predictors when separated by response variable. Since we have geolocation data, lets get an idea of where the positive labels are coming from by generating a cross-tabulation/bar plot and choropleth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.139877Z",
     "start_time": "2018-07-19T00:11:31.860Z"
    },
    "code_folding": [
     0,
     24,
     33
    ]
   },
   "outputs": [],
   "source": [
    "# mapping country codes to names\n",
    "cc = pd.read_csv('country_codes.csv')\n",
    "cc.columns = ['code', 'name']\n",
    "code_map = {str(code).lower():name for code, name in zip(cc.code.values, cc.name)}\n",
    "\n",
    "df['country'] = [code_map[v] if v in code_map.keys() else v for v in df.country.values]\n",
    "\n",
    "# create the cross-tabulation, normalized\n",
    "ct = pd.crosstab(df.country, df.edu, normalize='index')\n",
    "ct.drop(columns=0, inplace=True)\n",
    "\n",
    "# create a non-normalized cross tab to get the count of tickets per country\n",
    "temp = pd.crosstab(df.country, df.edu)\n",
    "ct['tickets'] = [a+b for a, b in zip(temp.iloc[:, 0], temp.iloc[:, 1])]\n",
    "ct = ct.sort_values(by=1, axis=0, ascending=False)\n",
    "\n",
    "# calculate the entire sample proportion\n",
    "total_prop = np.round(len(df.loc[df['edu'] == 1, :])/len(df.loc[df['edu'] == 0, :]), 3)\n",
    "print(f'The proportion of all tickets closed through education is {total_prop}.')\n",
    "\n",
    "n_countries = 25\n",
    "x = ct.index.values[2:n_countries]\n",
    "y = ct.iloc[2:n_countries, 0]\n",
    "\n",
    "data = go.Bar(\n",
    "        x=x,\n",
    "        y=y,\n",
    "        marker=dict(\n",
    "            color=Theme().GREY\n",
    "        ),\n",
    "        xaxis='x1',\n",
    "        yaxis='y1'\n",
    "    )\n",
    "layout = go.Layout(\n",
    "        title = 'Top performing countries',\n",
    "        xaxis = dict(tickangle = 45),\n",
    "        yaxis = dict(title='Proportion closed through education')\n",
    "    )\n",
    "\n",
    "fig = go.Figure(data=[data], layout=layout)\n",
    "iplot(fig, filename='top_countries')\n",
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.143032Z",
     "start_time": "2018-07-19T00:11:31.864Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# plot by percentage of tickets closed through education\n",
    "data = [\n",
    "    go.Choropleth(\n",
    "        locationmode = 'country names',\n",
    "        locations = ct.index.values,\n",
    "        z = ct.iloc[:, 0],\n",
    "        colorscale = [[0, Theme().TAN],[1, Theme().GREY]],\n",
    "        autocolorscale = False,\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(180,180,180)',\n",
    "                width = 0.5\n",
    "            )),\n",
    "        geo = 'geo'\n",
    "      )\n",
    "    ]\n",
    "# generate the layout\n",
    "layout = go.Layout(\n",
    "    title = 'Percentage of tickets closed through education',\n",
    "    geo = dict(\n",
    "        scope = 'world',\n",
    "        showcountries = True,\n",
    "        showframe = False,\n",
    "        showcoastlines = True,\n",
    "        showland = True,\n",
    "        landcolor = \"rgb(229, 229, 229)\",\n",
    "        countrycolor = \"rgb(255, 255, 255)\" ,\n",
    "        coastlinecolor = \"rgb(255, 255, 255)\",\n",
    "        projection = dict(\n",
    "            type = 'Mercator'\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout )\n",
    "iplot(fig, filename='world_map' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.145995Z",
     "start_time": "2018-07-19T00:11:31.867Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot by number of tickets\n",
    "data = [\n",
    "    go.Choropleth(\n",
    "        locationmode = 'country names',\n",
    "        locations = ct.index.values,\n",
    "        z = ct.tickets,\n",
    "        colorscale = [[0, Theme().TAN],[1, Theme().GREY]],\n",
    "        autocolorscale = False,\n",
    "        marker = dict(\n",
    "            line = dict (\n",
    "                color = 'rgb(180,180,180)',\n",
    "                width = 0.5\n",
    "            )),\n",
    "        geo = 'geo'\n",
    "      )\n",
    "    ]\n",
    "\n",
    "# generate the layout\n",
    "layout = go.Layout(\n",
    "    title = 'Number of tickets closed',\n",
    "    geo = dict(\n",
    "        scope = 'world',\n",
    "        showcountries = True,\n",
    "        showframe = False,\n",
    "        showcoastlines = True,\n",
    "        showland = True,\n",
    "        landcolor = \"rgb(229, 229, 229)\",\n",
    "        countrycolor = \"rgb(255, 255, 255)\" ,\n",
    "        coastlinecolor = \"rgb(255, 255, 255)\",\n",
    "        projection = dict(\n",
    "            type = 'Mercator'\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout )\n",
    "iplot(fig, filename='world_map' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most notable countries are displayed above. The particularly interesting countries are those that also have a considerable amount of tickets. It could be useful for the leadership team to evaluate the difference in business processes between these and countries in the lower proportions.\n",
    "\n",
    "Additionally, the United states has the highest number of tickets and is below the mean. Lets perform a large-value z-test to show how much statistical difference exists.\n",
    "\n",
    "$H_0: \\quad \\hat{p}_{us} - \\hat{p}_{world} = 0$\n",
    "\n",
    "$H_a: \\quad \\hat{p}_{us} - \\hat{p}_{world} \\ne 0$\n",
    "\n",
    "$Z: \\frac{\\hat{p}_{us}-\\hat{p}_{world}}{\\sqrt{\\hat{p}(1-\\hat{p}(1/n_{us}+1/n_{world}))}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.149133Z",
     "start_time": "2018-07-19T00:11:31.869Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# run the test\n",
    "us = 'United States of America'\n",
    "pa = ct.loc[us, 1]\n",
    "na = len(df.loc[df.country == us, 'country'])\n",
    "print(f'US proportion: {np.round(pa, 3)}, n: {na}')\n",
    "\n",
    "pb = np.mean(ct.loc[~(ct.index == 'us'), 1])\n",
    "nb = len(df.loc[df.country != us, 'country'])\n",
    "print(f'world proportion: {np.round(pb, 3)}, n: {nb}\\n')\n",
    "\n",
    "n  = na + nb\n",
    "ph = (n*pa+nb*pb)/(na+nb)\n",
    "se = np.sqrt(ph*(1-ph)*(1/na+1/nb))\n",
    "z  = abs(pa-pb)/se\n",
    "p  = 2*norm.sf(abs(z))\n",
    "dif   = pa-pb\n",
    "lower = dif-1.96*se\n",
    "upper = dif+1.96*se\n",
    "\n",
    "print(f'standard error: {np.round(se, 4)}')\n",
    "print(f'z score: {np.round(z, 4)}')\n",
    "print(f'p value: {np.round(p, 4)}')\n",
    "print(f'95% CI ({np.round(lower, 4)}, {np.round(upper, 5)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evidence strongly suggests that the proportion of tickets closed through education in the US is lower than the world mean proportion.\n",
    "\n",
    "For our last predictor, tenure, lets create a scatter plot of the mean proportion of successful tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.212678Z",
     "start_time": "2018-07-19T00:11:31.872Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# prop by tenure\n",
    "x = np.unique(sorted(df.tenure.tolist()))\n",
    "y = []\n",
    "c = []\n",
    "\n",
    "grouped = df.groupby('tenure', axis=0)\n",
    "for key in grouped.groups.keys():\n",
    "    a = np.sum(grouped.get_group(key).edu)\n",
    "    b = len(grouped.get_group(key).edu)\n",
    "    y.append(a/(a+b))\n",
    "    c.append(a+b)\n",
    "\n",
    "scat = go.Scatter(\n",
    "    x = x,\n",
    "    y = y,\n",
    "    mode = 'markers',\n",
    "    marker=dict(\n",
    "        color = c,\n",
    "        colorscale = [[0, Theme().GREY], [1, Theme().ORANGE]],\n",
    "        showscale=True,\n",
    "        opacity=.8\n",
    "    )\n",
    ")\n",
    "\n",
    "layout = go.Layout(\n",
    "    title='Proportion of positive response variable increases with tenure',\n",
    "    xaxis=dict(title='Months of tenure'),\n",
    "    yaxis=dict(title='Proportion of tickets closed through education')\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[scat], layout=layout)\n",
    "iplot(fig, filename='tenure_props')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.220194Z",
     "start_time": "2018-07-19T00:11:31.874Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# density\n",
    "mgr = df.loc[df.is_mgr  == True, 'tenure']\n",
    "ic  = df.loc[df.is_ic   == True, 'tenure']\n",
    "hist = [mgr, ic]\n",
    "\n",
    "labels = ['manager', 'IC']\n",
    "colors = [Theme().GREY, Theme().ORANGE]\n",
    "\n",
    "fig = figf.create_distplot(hist, labels, bin_size=[5, 5], colors=colors)\n",
    "fig['layout'].update(title='Density of tenure by career')\n",
    "iplot(fig, filename='tenure_density')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw some interesting conclusions from these visualizations. First, it appears as if the proportion of successful tickets begin to increase near 200 months of tenure. But more notably, most of the personnel in the range of increase are managers. Also notice that the majority of tickets being resolved are in the lower end of tenure meaning less mature, and lower ranking personnel are handling most tickets. This is somewhat expected behavior as managers rarely sit as on-call tech support.\n",
    "\n",
    "Another interesting characteristic is that neither IC or manager densities resemble the distribution of what should be a Poisson process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll generate a logistic regression model so we can see how each factor effects the probability of a ticket being closed through education. First, lets create the indicator variables and fit a LogisticRegression with L1 regularization. I'd like to see which variables contribute the most variance and eliminate those that do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.224421Z",
     "start_time": "2018-07-19T00:11:31.877Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "x = df.drop(columns=['edu', 'city', 'country', 'position', 'division', 'technician'])\n",
    "y = df.edu.values\n",
    "\n",
    "# generate indicator variables\n",
    "x  = pd.get_dummies(x)\n",
    "        \n",
    "# split and standardize\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42)\n",
    "\n",
    "scaler  = StandardScaler().fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test  = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-12T09:31:55.125011Z",
     "start_time": "2018-06-12T09:31:55.119148Z"
    }
   },
   "source": [
    "First, lets fit the model without regularization so we can interpret the coefficients. Scikit doesn't provide an option to not regularize so we'll set the regularization parameter to a level such that it'll make no difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.232500Z",
     "start_time": "2018-07-19T00:11:31.879Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(\n",
    "    penalty='l2', \n",
    "    C=1e9, \n",
    "    random_state=42\n",
    ").fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T00:22:13.236175Z",
     "start_time": "2018-07-19T00:11:31.884Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "coef = [dict(feature=b, coef=(a)) for a, b in zip(model.coef_[0], x.columns)]\n",
    "coef = sorted(coef, key=lambda x: x['coef'])\n",
    "\n",
    "bar = go.Bar(\n",
    "    x = [x['feature'] for x in coef],\n",
    "    y = [x['coef'] for x in coef],\n",
    "    marker = dict(color = Theme().GREY),\n",
    "    opacity = .9\n",
    ")\n",
    "layout = go.Layout(\n",
    "    title='Feature importance',\n",
    "    xaxis=dict(\n",
    "        title='feature',\n",
    "        tickangle=45\n",
    "    ),\n",
    "    yaxis=dict(title='magnitude of coefficient')\n",
    ")\n",
    "fig = go.Figure(data=[bar], layout=layout)\n",
    "iplot(fig, filename='feature_importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot makes me want to engineer some more features. Notice the most impacting feature is 'ticket_count', an engineered. This says that, when all other covariates are held constant, the probability of a ticket solved through education diminishes by over 30% for each new ticket! The next most important feature that reduces our probability is an indicator determining whether or not the person worked in an office. On the other end of the spectrum we have a few features that give us a boost: category_apps, building_mobile, and career_ic2 are the top three at .1, .08, and .07 respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "453px",
    "left": "777.692px",
    "right": "20px",
    "top": "127px",
    "width": "676px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
